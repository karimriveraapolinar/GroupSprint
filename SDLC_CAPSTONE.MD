# SDLC Capstone — Sprint 1 Process Analysis  
**Course:** Software Quality Assurance  

**Sprint:** Sprint 1  

**Model Selected:** V-Model

**Submission Type:** Solo  

**Due:** End of class Thursday  

---

## Section 1 — Model Selection and Rationale

<!-- 
Choose one SDLC model: Waterfall, Agile/Scrum, or V-Model. 
Argue that it best describes how Sprint 1 actually ran. 
Your rationale must connect specific model characteristics to specific evidence from your project — your spec, your GitHub Issues, your swap structure, your retrospective.

If you choose Waterfall: address why Sprint 1's feedback loops and iterative fixes do not disqualify it.  
If you choose V-Model: identify the specific parallel between your dev phases and your test phases. 
-->

**Selected Model:**  

**Rationale:**  

---

## Section 2 — Phase Analysis

<!-- 
Walk through every phase of your chosen model. For each phase, address two things:  
1. What element of Sprint 1 corresponds to this phase, even loosely?  
2. What would this phase have looked like under strict model adherence?  

Every phase must be addressed. Phases that don't map cleanly are not a reason to skip — they are the most valuable part of the analysis. 
-->

### Phase: <!-- e.g. Requirements / Planning / Sprint 1 / etc. -->

**What Sprint 1 produced:**  

**What strict adherence would have looked like:**  

---

### Phase: <!-- repeat for each phase of your chosen model -->

**What Sprint 1 produced:**  

**What strict adherence would have looked like:**  

---

### Phase:

**What Sprint 1 produced:**  

**What strict adherence would have looked like:**  

---

<!-- Add additional phase sections as needed for your chosen model -->

---

## Section 3 — Defect Case Studies

<!-- 
Select two bugs from your GitHub Issues filed during the Week 6 swap. For each bug provide:  
1. A description of the bug and what it caused  
2. The phase that introduced the defect (requirements / design / implementation)  
3. The phase that caught it — and whether your model would have caught it earlier  
4. The cost of catching it late  

Link directly to each GitHub Issue. 
-->

### Bug 1

**GitHub Issue:** <!-- link here -->  

**Description:**  

**Phase that introduced the defect:**  

**Phase that caught it:**  

**Would your chosen model have caught it earlier?**  

**Cost of catching it late:**  

---

### Bug 2

**GitHub Issue:** <!-- link here -->  

**Description:**  

**Phase that introduced the defect:**  

**Phase that caught it:**  

**Would your chosen model have caught it earlier?**  

**Cost of catching it late:**  

---

## Section 4 — QA Assessment

<!-- 
Address three things:  
1. How did QA actually operate during Sprint 1? (Gate / continuous / in between?)  
2. How does that compare to what your chosen model prescribes?  
3. What would QA have looked like under strict model adherence?  

Your answer must be specific to your team's Sprint 1 experience. 
-->

**How QA actually operated:**  

**How that compares to your chosen model:**  

**What QA would have looked like under strict adherence:**  

---

## Section 5 — Team Retrospective on Process

<!-- 
Identify the single most significant gap between how Sprint 1 ran and how it would have run under strict adherence to your chosen model.  

Answer three things:  
1. What was the gap?  
2. What did it cost your team in practice?  
3. If you ran Sprint 2 under strict model adherence, what one change would have the most impact? 
-->

**The gap:**  

**What it cost the team:**  

**The one change for Sprint 2:**  

## Contributors:
Karim    **Roles Led:** All


